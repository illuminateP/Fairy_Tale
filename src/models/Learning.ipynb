{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10PNS_iPUkQ-",
        "outputId": "5ff1b77a-bead-46ae-b855-55a87a7cf1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import"
      ],
      "metadata": {
        "id": "WbzmNkyujZIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    BertTokenizerFast, BertForQuestionAnswering,\n",
        "    TrainingArguments, Trainer\n",
        ")"
      ],
      "metadata": {
        "id": "mbOs_7wZjYcn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 경로 지정"
      ],
      "metadata": {
        "id": "JkVBvbEzjbVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/drive/MyDrive/NLP (1)/training.json\"\n",
        "val_path   = \"/content/drive/MyDrive/NLP (1)/validation.json\"\n",
        "model_ckpt = \"beomi/kcbert-base\""
      ],
      "metadata": {
        "id": "CPkNkyJ2jcSX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 불러오기"
      ],
      "metadata": {
        "id": "vwlYyRCZjfFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(model_ckpt)\n",
        "tokenizer.model_max_length = 300            # ← 300 이하로 고정\n",
        "MAX_LEN   = 256                             # 실제 입력 길이\n",
        "DOC_STRIDE = 128                            # 슬라이딩 윈도\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(model_ckpt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GcL6K20jg0-",
        "outputId": "94fb61bc-3c0d-4a4d-ea23-c37ddd07ce41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "85X40DhMjiDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(json_path):\n",
        "    with open(json_path, encoding=\"utf-8\") as f:\n",
        "        raw = json.load(f)[\"data\"]\n",
        "    buf = []\n",
        "    for art in raw:\n",
        "        for para in art[\"paragraphs\"]:\n",
        "            ctx = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                for ans in qa[\"answers\"]:\n",
        "                    buf.append({\n",
        "                        \"id\"     : qa[\"id\"],\n",
        "                        \"context\": ctx,\n",
        "                        \"question\": qa[\"question\"],\n",
        "                        \"answer_text\" : ans[\"text\"],\n",
        "                        \"answer_start\": ans[\"answer_start\"],\n",
        "                    })\n",
        "    return buf\n",
        "\n",
        "train_samples = flatten(train_path)\n",
        "val_samples   = flatten(val_path)\n",
        "\n",
        "\n",
        "class KorQuAD(Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = samples\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.samples[idx]\n",
        "\n",
        "        enc = tokenizer(\n",
        "            ex[\"question\"], ex[\"context\"],\n",
        "            max_length=MAX_LEN,\n",
        "            truncation=\"only_second\",\n",
        "            stride=DOC_STRIDE,\n",
        "            return_overflowing_tokens=False,\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        offset = enc.pop(\"offset_mapping\")[0]\n",
        "        ans_s, ans_e = ex[\"answer_start\"], ex[\"answer_start\"] + len(ex[\"answer_text\"])\n",
        "\n",
        "        tok_start = tok_end = None\n",
        "        for i, (s, e) in enumerate(offset):\n",
        "            if s <= ans_s < e: tok_start = i\n",
        "            if s <  ans_e <= e: tok_end   = i\n",
        "        # 답이 잘려 나가면 샘플 drop\n",
        "        if tok_start is None or tok_end is None:\n",
        "            return self.__getitem__((idx+1)%len(self))   # 재귀로 다음 샘플\n",
        "\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"start_positions\"] = torch.tensor(tok_start)\n",
        "        item[\"end_positions\"]   = torch.tensor(tok_end)\n",
        "        return item\n",
        "\n",
        "train_ds = KorQuAD(train_samples)\n",
        "val_ds   = KorQuAD(val_samples)"
      ],
      "metadata": {
        "id": "bOjcC4p2jlNS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련하기"
      ],
      "metadata": {
        "id": "PcYBp6t6jl0_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "YOFyva11PZO4",
        "outputId": "f58b3f0c-2600-4ef4-b29a-f54161836ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2187846205>:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='29020' max='29020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29020/29020 1:15:59, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.804200</td>\n",
              "      <td>0.794534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.519600</td>\n",
              "      <td>0.786869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.330600</td>\n",
              "      <td>0.984986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.182900</td>\n",
              "      <td>1.456881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.072800</td>\n",
              "      <td>1.734986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=29020, training_loss=0.4284141697775159, metrics={'train_runtime': 4560.6064, 'train_samples_per_second': 50.901, 'train_steps_per_second': 6.363, 'total_flos': 3.032871455434752e+16, 'train_loss': 0.4284141697775159, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir       = \"/content/qa-out\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy    = \"epoch\",\n",
        "    learning_rate    = 5e-5,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size  = 8,\n",
        "    num_train_epochs = 5,\n",
        "    weight_decay     = 0.01,\n",
        "    report_to        = \"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model         = model,\n",
        "    args          = training_args,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset  = val_ds,\n",
        "    tokenizer     = tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가하기"
      ],
      "metadata": {
        "id": "EbN4vv4Cqmxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────── flatten 후 그대로 보존 ──────────\n",
        "train_samples = flatten_korquad(train_path)   # ← answers 포함\n",
        "val_samples   = flatten_korquad(val_path)     # ← answers 포함\n",
        "\n",
        "# … Dataset/Trainer 코드 …\n",
        "\n",
        "# ----------  예측 ----------\n",
        "start_logits, end_logits = trainer.predict(val_ds).predictions\n",
        "\n",
        "# ----------  gold │ pred ----------\n",
        "pred_texts = []\n",
        "for (s_log, e_log), enc in zip(zip(start_logits, end_logits), val_ds):\n",
        "    s = int(np.argmax(s_log));  e = int(np.argmax(e_log))\n",
        "    if e < s: e = s\n",
        "    pred_texts.append(\n",
        "        tokenizer.decode(enc[\"input_ids\"][s:e+1], skip_special_tokens=True).strip()\n",
        "    )\n",
        "\n",
        "gold_texts = [sample[\"answers\"][\"text\"][0] for sample in val_samples]  # ★ 여기 수정\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ps7PpaQC2XNN",
        "outputId": "6dd8c041-1fc2-4bed-d947-5a5eda5c8bb1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'flatten_korquad' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1959053799>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ────────── flatten 후 그대로 보존 ──────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_korquad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# ← answers 포함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_samples\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mflatten_korquad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# ← answers 포함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# … Dataset/Trainer 코드 …\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'flatten_korquad' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "KYYgy7XbPpwC",
        "outputId": "66807281-dc3d-4295-fb51-ce1b4f4c30e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'answers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3560849355>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpred_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mgold_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# ── 4. 지표 집계 ───────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-3560849355>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpred_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mgold_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# ── 4. 지표 집계 ───────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'answers'"
          ]
        }
      ],
      "source": [
        "import re, string, collections, numpy as np\n",
        "from itertools import zip_longest\n",
        "\n",
        "# ── 1. SQuAD 공식 정규화 · 토큰화 ──────────────────────────\n",
        "def _normalize(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = \"\".join(ch for ch in text if ch not in string.punctuation)\n",
        "    text = re.sub(r\"\\b(a|an|the)\\b\", \" \", text)        # 관사 제거\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "def _tok(text: str):\n",
        "    return _normalize(text).split()\n",
        "\n",
        "# ── 2. 메트릭 함수 (Exact-Match / F1) ──────────────────────\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(_normalize(pred) == _normalize(gold))\n",
        "\n",
        "def f1_squad(pred: str, gold: str) -> float:\n",
        "    p_toks, g_toks = map(_tok, (pred, gold))\n",
        "    common = collections.Counter(p_toks) & collections.Counter(g_toks)\n",
        "    same = sum(common.values())\n",
        "    if same == 0:\n",
        "        return 0.0\n",
        "    precision = same / len(p_toks)\n",
        "    recall    = same / len(g_toks)\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "# ── 3. 검증 셋 inference → 예측 문자열 ─────────────────────\n",
        "start_logits, end_logits = trainer.predict(val_ds).predictions\n",
        "pred_texts = []\n",
        "for (s_log, e_log), sample in zip(zip(start_logits, end_logits), val_ds):\n",
        "    s = int(np.argmax(s_log));  e = int(np.argmax(e_log))\n",
        "    if e < s:                   e = s\n",
        "    text = tokenizer.decode(sample[\"input_ids\"][s:e+1],\n",
        "                            skip_special_tokens=True).strip()\n",
        "    pred_texts.append(text)\n",
        "\n",
        "gold_texts = [ex[\"answers\"][\"text\"][0] for ex in val_samples]\n",
        "\n",
        "# ── 4. 지표 집계 ───────────────────────────────────────────\n",
        "EM  = np.mean([exact_match(p, g) for p, g in zip_longest(pred_texts, gold_texts, fillvalue=\"\")])\n",
        "F1  = np.mean([f1_squad (p, g)   for p, g in zip_longest(pred_texts, gold_texts, fillvalue=\"\")])\n",
        "loss_val = trainer.evaluate(eval_dataset=val_ds).get(\"eval_loss\", float(\"nan\"))\n",
        "\n",
        "print(f\"📊  Validation │ Loss={loss_val:.4f} │ EM={EM:.4f} │ F1={F1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── 5. 데모: 임의 샘플로 QA 인터랙션 ───────────────────────\n",
        "def ask_demo(idx:int=None):\n",
        "    \"\"\"idx 없으면 검증셋 첫 항목 사용\"\"\"\n",
        "    sample = val_samples[idx or 0]\n",
        "    context = sample[\"context\"]\n",
        "    print(\"─ 지문 ─\")\n",
        "    print(context[:400], \"...\" if len(context)>400 else \"\")  # 길면 잘라서 표시\n",
        "    print(\"\\n(※ 위 지문 일부만 표시 - 전체는 model 에 입력됩니다)\\n\")\n",
        "    q = input(\"🗨️  질문을 입력하세요: \").strip()\n",
        "    enc = tokenizer(q, context,\n",
        "                    truncation=\"only_second\", max_length=512,\n",
        "                    return_offsets_mapping=False, return_tensors=\"pt\").to(trainer.model.device)\n",
        "    with torch.no_grad():\n",
        "        out = trainer.model(**enc)\n",
        "    s = int(out.start_logits.argmax()); e = int(out.end_logits.argmax())\n",
        "    if e < s: e = s\n",
        "    answer = tokenizer.decode(enc[\"input_ids\"][0][s:e+1],\n",
        "                              skip_special_tokens=True).strip()\n",
        "    print(f\"🤖  답변: {answer}\")\n",
        "\n",
        "# 사용 예시\n",
        "ask_demo(2)     # 셀 실행 후 콘솔에 질문 입력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc7668rz2FBu",
        "outputId": "71556b32-7c72-44fa-8349-8749276149ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "─ 지문 ─\n",
            "어느 마을에 릴리엔탈과 구스타프라는 형제가 살았어. 릴리엔탈과 구스타프는 어릴 때부터 하늘을 자유롭게 날아다니는 새를 부러워했어. 그래서 날마다 언덕에 올라 하늘을 나는 새를 구경하곤 했지. \n",
            "\n",
            "(※ 위 지문 일부만 표시 - 전체는 model 에 입력됩니다)\n",
            "\n",
            "🗨️  질문을 입력하세요: 릴리엔탈은 무엇을 부러워했나요?\n",
            "🤖  답변: 하늘을 자유롭게 날아다니는 새\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save"
      ],
      "metadata": {
        "id": "LeaIY-wEpr6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저를 원하는 경로에 저장\n",
        "save_path = './my_model'  # colab 내 디렉토리명\n",
        "\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "mfn1RH_appv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('my_model', 'zip', './my_model')"
      ],
      "metadata": {
        "id": "7yqDsxpnpx0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}